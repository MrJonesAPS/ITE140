{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run ./load_concatenated_text.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "#Here's a list of words that aren't in the spell checker but that we should probably preserve\n",
    "#We'll probably need to iterate on this list\n",
    "spell.word_frequency.load_words([\n",
    "    'Arlington'\n",
    "    , 'Glebe'\n",
    "    , 'Ballston'\n",
    "    , 'Rosslyn'\n",
    "    , 'Pershing'\n",
    "    , 'Rockville'\n",
    "    , 'MD'\n",
    "    , 'VA'\n",
    "    , 'Maryland'\n",
    "    , 'Virginia'\n",
    "    , 'Bluemont'\n",
    "    , 'Wilson'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to spell-check text. We'll use apply() to run this function on every record\n",
    "def spell_check(text):\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    corrected_words = []\n",
    "    \n",
    "    # Find misspelled words\n",
    "    misspelled = spell.unknown([token.text for token in doc if not token.is_punct and not token.is_stop])\n",
    "\n",
    "    for token in doc:\n",
    "        if not token.is_punct and not token.is_stop and len(token.text.strip()) > 0:  # Exclude punctuation and stop words\n",
    "            word = token.text.strip()\n",
    "            if word.lower() in misspelled:\n",
    "                correction = spell.correction(word)\n",
    "                if (correction is not None) and (correction.lower() != word.lower()):\n",
    "                    corrected_words.append(correction)\n",
    "                    #Uncomment this line to review the list of words that are correcting\n",
    "                    #print(f\"Correcting {word} => {correction}\")\n",
    "                else:\n",
    "                   corrected_words.append(word.lower())\n",
    "            else:\n",
    "                corrected_words.append(word)  # Preserve correct words\n",
    "\n",
    "    if len(corrected_words)>0:\n",
    "        return \" \".join(corrected_words)\n",
    "    else: \n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the spell-checking function to the DataFrame\n",
    "df_all_postcards['spell_checked_text'] = df_all_postcards['concatenated_text'].apply(spell_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the result\n",
    "df_all_postcards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

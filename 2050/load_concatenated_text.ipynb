{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2050 Data Loading\n",
    "\n",
    "This notebook loads all of the Arlington 2050 data from files, does minimal cleaning, and outputs a single Pandas DataFrame that has two columns:\n",
    "\n",
    "- **concatenated_text**: This combines all of the text from the entire postcard submission. Depending on the specific source dataset, this might involve a lot of cleaning. If the data includes english translations, only the english data is kept.\n",
    "- **source**: a text column that describes the source of the data. Eg \"County Fair\"\n",
    "\n",
    "\n",
    "TODO: Add spell checking with pyspellchecker. I kept the import here so that I can add it later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install ipython ipykernel ipywidgets\n",
    "pip install spacy\n",
    "python -m spacy download en_core_web_md\n",
    "pip install plotly\n",
    "pip install scikit-learn\n",
    "pip install pandas\n",
    "pip install openpyxl\n",
    "pip install pyspellchecker\n",
    "pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# initialize models\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all of the datasets into separate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file into a pandas DataFrame\n",
    "df_countyfair = pd.read_excel('data/Digitized postcards from County Fair_August  23-25 2024.xlsx')\n",
    "df_hispanicfest = pd.read_excel('data/Digitized postcards from Hispanic Heritage Community Festival in Tyrol Hill Park_Sep 7 2024.xlsx')\n",
    "df_web = pd.read_excel('data/Public Input Potcards Exported 10-01-24.xlsx')\n",
    "df_events = pd.read_excel('data/Postcard text tracker.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now clean the data. These spreadsheets are all slightly different, so i'm trying to get them all to the same subset of columns. \n",
    "\n",
    "Eventually, I might come back and try to find extra data in individual spreadsheets that might be interesting to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# County Fair\n",
    "###\n",
    "# Drop the first two rows\n",
    "df_countyfair = df_countyfair.drop([0, 1]).reset_index(drop=True)\n",
    "\n",
    "# Clean up the columns\n",
    "df_countyfair.columns = ['id', 'first', 'first_translated', 'second', 'second_translated']\n",
    "\n",
    "# Create a single column that concatenates the text from the other columns\n",
    "def concatenate_text(row):\n",
    "    text = \"\"\n",
    "    if pd.notna(row['first_translated']):\n",
    "        text += row['first_translated']\n",
    "    elif pd.notna(row['first']):\n",
    "        text += row['first']\n",
    "    \n",
    "    if pd.notna(row['second_translated']):\n",
    "        text += \". \" + row['second_translated']\n",
    "    elif pd.notna(row['second']):\n",
    "        text += \". \" + row['second'] \n",
    "\n",
    "    return text\n",
    "\n",
    "df_countyfair['concatenated_text'] = df_countyfair.apply(concatenate_text, axis=1)\n",
    "df_countyfair['source'] = \"County Fair\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Hispanic Heritage Fest\n",
    "###\n",
    "# Drop the first two rows\n",
    "df_hispanicfest = df_hispanicfest.drop([0, 1]).reset_index(drop=True)\n",
    "\n",
    "# Clean up the columns\n",
    "df_hispanicfest.columns = ['id', 'first', 'first_translated', 'second', 'second_translated']\n",
    "\n",
    "# Create a single column that concatenates the text from the other columns\n",
    "def concatenate_text(row):\n",
    "    text = \"\"\n",
    "    if pd.notna(row['first_translated']):\n",
    "        text += row['first_translated']\n",
    "    elif pd.notna(row['first']):\n",
    "        text += row['first']\n",
    "    \n",
    "    if pd.notna(row['second_translated']):\n",
    "        text += \". \" + row['second_translated']\n",
    "    elif pd.notna(row['second']):\n",
    "        text += \". \" + row['second'] \n",
    "\n",
    "    return text\n",
    "\n",
    "df_hispanicfest['concatenated_text'] = df_hispanicfest.apply(concatenate_text, axis=1)\n",
    "df_hispanicfest['source'] = \"Hispanic Heritage Fest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Web form\n",
    "###\n",
    "\n",
    "# Clean up the columns\n",
    "df_web.columns = ['id', 'zip', 'source', 'first', 'first_gettinghere','second','third','zip_selfreported','zip_selfreported2']\n",
    "\n",
    "# Create a single column that concatenates the text from the other columns\n",
    "def concatenate_text(row):\n",
    "    text = \"\"\n",
    "    if pd.notna(row['first']):\n",
    "        text += row['first']\n",
    "    if pd.notna(row['first_gettinghere']):\n",
    "    \n",
    "        text += row['first_gettinghere']     \n",
    "    if pd.notna(row['second']):\n",
    "        text += row['second']\n",
    "    if pd.notna(row['third']):\n",
    "        text += row['third']\n",
    "\n",
    "    return text\n",
    "\n",
    "df_web['concatenated_text'] = df_web.apply(concatenate_text, axis=1)\n",
    "df_web['source'] = \"web\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Postcards from events\n",
    "###\n",
    "# Drop the first two rows\n",
    "df_events = df_events.dropna(subset=['Postcard #', 'Text'])\n",
    "\n",
    "# Clean up the columns\n",
    "df_events.columns = ['id', 'concatenated_text','ignore','source','themes','language','demographics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all of these into a single dataframe, with concatenated text and source.\n",
    "df_all_postcards = pd.concat([\n",
    "        df_countyfair[['concatenated_text','source']]\n",
    "        ,df_hispanicfest[['concatenated_text','source']]\n",
    "        ,df_web[['concatenated_text','source']]\n",
    "        ,df_events[['concatenated_text','source']]\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"here's the number of records from each event:\n",
    "      Hispanic Heritage Fest: {df_hispanicfest.shape[0]}\n",
    "        County Fair: {df_countyfair.shape[0]}\n",
    "        Website: {df_web.shape[0]}\n",
    "        Other Events: {df_events.shape[0]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_postcards.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
